# JIT compiler

## 1. JIT 컴파일러 개요

![82E2A35E-72EF-4198-A232-3FE47CA56ED1.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/829c780e-4eb8-4d84-8397-f3e7fe879e33/82E2A35E-72EF-4198-A232-3FE47CA56ED1.png)

저스트 인 타임(just-in-time, JIT) 컴파일러는 JVM의 핵심입니다. JVM 내에서 컴파일러보다 성능에 더 영향을 주는 요소는 없습니다.

런타임 시 바이트코드를 원시 시스템 코드로 컴파일하여 Java 애플리케이션의 성능을 향상시키는 런타임 환경의 컴포넌트의 역할을 수행합니다

다행스럽게도 대부분의 상황에서 이후에 나올 티어드 컴파일(tiered compilation)을 사용하기만 해도 튜닝할 필요는 거의 없습니다.

이 글에서는 컴파일러에 대해 다소 심도 있게 다루겠습니다. 컴파일러의 동작 방법에 대한 일부 정보로 시작해서 JIT 컴파일러의 사용에 대한 장점과 단점을 논의하겠습니다.

그 다음 어떤 자바 버전에 어떤 종류의 컴파일러가 들어있는지에 대해 주제를 옮겨서 설명하겠습니다.

마지막으로 컴파일러의 중급과 고급 튜닝 일부를 다루겠습니다. 이렇게 튜닝하면 애플리케이션의 성능에서 최후의 몇 퍼센트라도 올릴 수 있습니다.

### 컴파일과 인터프리트

CPU는 어셈블리나 바이너리 코드라고 불리는 특정 명령어만을 실행시킬 수 있습니다. 그 말은 CPU가 실행하는 모든 프로그램은 이 명령어들로 변환이 가능합니다.

C++와 Forttran과 같은 언어들은 바이너리 (컴파일된) 코드로 실행되어 컴파일형 언어라고 불립니다.

즉 프로그램이 작성되고 정적 컴파일러는 바이너리를 생성합니다. 그 바이너리 내의 어셈블리 코드는 **특정 CPU**만을 대상으로 합니다.

반면 PHP나 Perl과 같은 언어는 인터프리트 됩니다. 동일한 프로그램 소스 코드는 머신이 같은 인터프리터라고 불리는 프로그램을 갖고 있으면 어떤 CPU에서든 실행이 가능합니다.

인터프리터는 각 라인이 실행되면서 프로그램의 각 코드를 한 줄씩 바이너리 코드로 번역합니다.

두 방식의 차이를 보겠습니다.

인터프리터 언어로 작성된 프로그램은 컴파일 언어보다 이식성이 높습니다. 동일한 코드를 짜서 적절한 인터프리터가 있는 머신에 올리고 실행시킬 수 있습니다.

하지만 컴파일 언어보다 빠르게 실행되지는 않습니다. 간단한 예로 하나의 루프에서 작업하는 일이 있다고 생각해보면 인터프리터는 루프 내에서 실행될 때 코드의 각 줄을 다시 번역합니다. 컴파일된 코드는 되풀이해서 번역할 필요가 없습니다.

그리고 바이너리를 생성할 때 컴파일러가 할 수 있는 역할은 더 많습니다.

그 중 관련된 건 바이너리 문장의 순서 입니다. 모든 어셈블리 언어 명령어는 실행하는데 동일한 시간이 걸리지 않습니다.

두 개의 레지스터 내에 저장된 값을 더하는 문장은 한 번 실행되지만 덧셈에 필요한 값을 메모리에 조회하는데는 여러 번의 주기를 가질 것입니다.

그러므로 컴파일러는 이러한 문장의 순서를 이해하고 먼저 데이터를 로딩하기 위한 어셈블리 명령을 실행한 후 덧셈을 하도록 순서를 바꿀 것입니다.

하지만 인터프리터는 메모리에서 데이터를 요청하고 이용할 때까지 기다린 다음 덧셈을 할 것 입니다.

이러한 이유로 인해 인터프리트된 코드는 언제나 컴파일된 코드보다 느릴 것입니다.

자바는 여기서 절충안을 찾으려고 시도합니다. 자바 애플리케이션은 컴파일되지만 특정 CPU에 맞는 특정 바이너리로 컴파일 되는게 아니라 대신 최적화된 어셈블리 언어인 바이트 코드로 컴파일 됩니다.

이는 JVM이 있는 환경이라면 어디서든 실행시킬 수 있는 독립적인 플랫폼을 제공합니다. 그리고 JVM 내의 인터프리터로 최적화된 바이트 코드를 실행하면서 JIT 컴파일러로 바이너리로 컴파일 할 수 있습니다.

참고로 예전 자바는 인터프리터 방식만을 사용했다고 합니다. 인터프리터의 경우 명령어를 하나씩 실행하는 방식으로 각각의 명령어 단위로 본다면 실행 속도가 빠르지만 큰 덩어리로 본다면 속도가 느린 방식입니다. 중복되는 코드가 있어도 라인별로 실행하기에 다시 인터프리팅하는 과정이 들어가기에 해당 문제점을 보완하고자 JIT Compilet가 나오게 됩니다

---

## 2. 핫스팟 컴파일

핫스팟이란 이름은 코드 컴파일에 대한 접근법에서 유래했습니다. 일반적인 프로그램은 전체 코드 중 일부만 자주 실행되며 애플리케이션의 성능은 이 일부가 얼마나 빠르게 실행되는가에 의해 좌우됩니다.

이 중요한 영영을 애플리케이션의 핫스팟이라고 합니다. 그 영역의 코드가 많이 실행될수록 더욱 핫해집니다.

이런 이유로 JVM은 코드를 실행할 때 바로 코드 컴파일을 하지 않습니다. 여기에는 기본적인 이유가 두 가지가 있습니다.

1. 첫째, 코드가 한 번만 실행된다면 컴파일은 헛수고다. 컴파일해서 컴파일된 코드를 한번만 실행하는 것보다 자바 바이트코드를 인터프리트하는 편이 더 빠를 것이다.
2. 둘째, 최적화 때문입니다. JVM이 특정 메소드나 루프를 실행하는 시간이 길어질 수록 **코드에 대해 얻어지는 정보가 많습니다.** 이를 통해 JVM이 코드를 컴파일할 때 최적화를 많이 적용할 수 있습니다.

첫번째 이유의 경우 자주 호출되는 메소드거나 많이 반복되는 루프라면 컴파일할 가치가 있습니다. 컴파일러는 반드시 컴파일하기에 충분할 정도로 자주 호출되는 메소드를 알아낼 수 있습니다. 이는 뒤에서 설명하겠습니다.

가장 중요한 최적화 중 하나인 레지스트리와 메인 메모리 최적화 예시를 설명하겠습니다.

```
public class RegisterTest{
    private int sum;

    public void calculateSum(int n){
        for(int i=0;i<=n;i++){
            sum += i;
        }
    }

}
```

이 예에서 인스턴스 변수인 sum은 메인 메모리 내에 있어야 하지만 메인 메모리에서 매번 값을 검색한다면 성능은 형편 없을 것입니다.

최적화를 한다면 컴파일러는 sum의 초기값을 레지스터에 로드하고 레지스터내의 값을 이용해 루프를 수행한 후 메인 메모리에 결과 값을 저장할 것입니다.

이 최적화는 매우 효과적이지만 스레드 동기화에서는 좀 다르게 적용될 것입니다. 왜냐하면 스레드는다른 스레드가 사용하는 레지스터의 값을 조회할 수 없기 때문입니다.

동기화를 한다면 레지스터에서 메인 메모리로 저장되어 다른 스레드들이 이용 가능한 시기를 알려줘야 합니다.

두번째 이유에 대해 간단히 예시를 들겠습니다.

```
b = obj1.equals(obj2);
```

equals() 메소드의 경우 모든 자바 객체에서 사용할 수 있는 메소드이며 흔히 오버라이드 됩니다.

인터프리터는 위의 문장에 맞닥뜨릴 때 실행시킬 equals() 메소드가 뭔지 알기 위해서 obj1의 타입을 찾기 위해 동적 look up을 해야 합니다. 이는 꽤 시간이 걸립니다.

시간이 흐르면서 이 문장을 많이 실행 해봤고 매번 obj1의 타입이 java.lang.String 이라는 사실을 알게되었다고 가정해봅시다. 그러면 JVM은 obj1.equals()를 String.equals()로 최적화한 코드를 만들 수 있습니다.

---

## 3. 기본 튜닝 (서버와 클라이언트 컴파일러)

JIT 컴파일러는 두 가지 형태로 나뉩니다. 사용할 형태는 흔히 애플리케이션이 실행 되고 있을 때 해야 할 컴파일러 튜닝에 따라 결정됩니다.

두 개의 컴파일러는 클라이언트와 서버로 알려져 있습니다.

JVM 개발자들은 흔히 c1(컴파일러 1, 클라이언트 컴파일러)와 c2(컴파일러 2, 서버 컴파일러)라는 이름으로 부릅니다.

두 컴파일러의 주요 차이점은 코드 컴파일에 있어서 적극성의 유무 입니다.

클라이언트 컴파일러는 서버 컴파일러보다 먼저 컴파일하기 시작합니다. 이는 서버 컴파일러보다 상대적으로 더 많은 코드를 컴파일 한다는 의미이며 코드가 실행되기 시작하는 시간동안 클라이언트 컴파일러가 보다 더 빠를 것입니다.

서버 컴파일러는 클라이언트 컴파일러보다 더 많은 정보를 바탕으로 컴파일을 하고 더 나은 최적화를 제공합니다. 결국 애플리케이션이 장기간 작동을 한다면 서버 컴파일러가 클라이언트 컴파일러보다 더 빠를 것입니다.

각각의 컴파일러에 대한 트레이드 오프는 프로그램이 수행되는 기간과 초기 스타트업 시간의 중요도를 바탕으로 선택합니다.

여기서 한가지 의문이 있을 수 있습니다.

JVM이 시작할 땐 클라이언트 컴파일러로 작동하다가 코드가 많이 호출되면 서버 컴파일러로 바꿀 순 없을까? 이 기법은 티어드 컴파일(tiered compilation)이라고 합니다.

티어드 컴파일을 이용하면 코드는 먼저 클라이언트 컴파일러로 컴파일 되고 많이 쓰이게 되면 역최적화 후 서버 컴파일러로 재컴파일 됩니다. 재컴파일 되는 시간은 성능에 영향을 줄 정도로 크지 않습니다.

티어드 컴파일은 자바 7부터 릴리즈 되었으며 자바 8에서는 기본으로 사용할 수 있습니다.

### 스타트업 최적화

빠른 스타트업이 주목적일 때 클라이언트 컴파일러가 가장 자주 사용됩니다.

**표. 다양한 애플리케이션 스타트업 시간**

| 애플리케이션 | -client | -server | -XX:+TieredCompilation |
| --- | --- | --- | --- |
| HelloWorld | 0.08 | 0.08 | 0.08 |
| NetBeans | 2.83 | 3.92 | 3.07 |
| BigApp | 51.5 | 54.0 | 52.0 |

단순한 HelloWorld 어플리케이션은 컴파일러가 어떤 기여도 할 수 없기 때문에 유리한 컴파일러가 없습니다.

NetBeans은 중간 크기의 자바 GUI 애플리케이션입니다. 스타트업할 때 약 10,000개의 클래스를 로드하고 몇개의 그래픽 객체를 초기화시키는 등의 작업을 합니다.

여기서 클라이언트 컴파일러는 스타트업할 때 매우 유리합니다. 서버 컴파일러는 38.5% 늦게 시작하며 1초 가량으로 뚜렷한 차이를 보입니다.

여기서 티어드 컴파일러도 클라이언트 컴파일러보다 약 8% 느리다는 점에 주목하면 됩니다.

GUI 프로그램 같은 경우는 더 빨리 시작할 수록 사용자에게 더 성능이 좋다고 느껴지는 프로그램입니다.

만약 전반적인 성능이 확실히 더 중요하다고 느껴지는 경우가 아니라면 클라이언트 컴파일러를 사용하는게 맞습니다.

BigApp 같은 경우는 20,000개 이상의 클래스를 로드하고 막대한 초기화를 수행하는 대규모 서버 프로그램입니다. 이 프로그램의 초기 스타트업의 영향은 컴파일러보단 디스크에서 읽어야 하는 JAR 파일의 개수 입니다. 클라이언트 컴파일러를 사용한다고 눈에 띄는 이점은 별로 없을 것입니다.

### 배치 동작 최적화

고정된 양의 작업을 수행하는 배치 어플리케이션에서 컴파일러의 선택은 중요한 요소입니다.

다음 배치 어플리케이션 예제를 통해 살펴보겠습니다.

**표. 배치 애플리케이션 작업 완료 시간**

| 주식의 개수 | -client | -server | -XX:+TieredCompilation |
| --- | --- | --- | --- |
| 1 | 0.142 초 | 0.176 초 | 0.165 초 |
| 10 | 0.211 초 | 0.348 초 | 0.226 초 |
| 100 | 0.454 초 | 0.674 초 | 0.472 초 |
| 1000 | 2.556 초 | 2.158 초 | 1.916 초 |
| 10000 | 23.78 초 | 14.03 초 | 13.56 초 |

이 애플리케이션은 1~10000개의 주식에 대해 1년치의 이력 (평균과 표준편차)를 요청하는 애플리케이션 입니다.

1~100 개의 작업을 할 땐 클라이언트 컴파일러가 더 빨리 작업을 완료 했습니다. 그 후 성능상의 이점은 서버 컴파일러와 티어드 컴파일러 쪽으로 기웁니다.

티어드 컴파일이 항상 표준 서버 컴파일러보다 약간 더 성능상에 우위가 있다는 점도 흥미롭습니다.

이론상으로 일단 프로그램의 핫스팟을 전부 컴파일하기 충분할 정도로 스타트업 됐다면 서버 컴파일러의 성능이 더 나을 것으로 예상할 수 있습니다.

하지만 애플리케이션은 거의 항상 드물게 실행되는 작은 영역의 코드를 가지고 있고 티어드 컴파일러는 이 부분을 컴파일 했겠지만 서버 컴파일러는 인터프리트 모드로 실행했을 것입니다.

### 장기 수행 어플리케이션 최적화

마지막으로 장기 수행 어플리케이션에서 컴파일러의 성능 차이를 보겠습니다.

장기 수행 어플리케이션은 전형적으로 코드의 주요 부분이 전부 컴파일될 정도로 충분히 오래 실행됐다는 의미입니다.

다음 예제는 0, 60, 300초의 준비 기간 후 60초 동안 측정을 합니다. 그 후 서버가 초당 몇개의 작업을 했는지 보여주는 예제입니다.

**표. 서버 애플리케이션의 처리율**

| 준비 기간 | -client | -server | -XX:+TieredCompilation |
| --- | --- | --- | --- |
| 0 | 15.87 | 23.72 | 24.23 |
| 60 | 16.00 | 23.73 | 24.26 |
| 300 | 16.85 | 24.42 | 24.43 |

여기서 측정 기간은 60초이므로 준비 기간이 0초라도 충분히 컴파일러는 핫스팟을 컴파일할 기회가 많습니다. 그러므로 이 예제에서는 서버 컴파일러 쪽이 더 낫습니다.

앞의 내용과 같이 티어드 컴파일은 단독 서버 컴파일러보다 코드를 조금 더 많이 컴파일하고 조금 더 나은 성능을 쥐어짜낼 수 있습니다.
